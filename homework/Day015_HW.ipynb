{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 15s 0us/step\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0310 00:50:12.782922 140430536947520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0310 00:50:12.846381 140430536947520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 33s 667us/step - loss: 1.3554 - acc: 0.5383\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.8469 - acc: 0.7015\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 0.5977 - acc: 0.7898\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.3954 - acc: 0.8621\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.2547 - acc: 0.9122\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 0.1779 - acc: 0.9387 - ETA: 0s - loss: 0.1775 - acc: 0.\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.1392 - acc: 0.95022s - loss: 0.1350 - acc: 0.951 - ET\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.1206 - acc: 0.9575\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.1009 - acc: 0.9647\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0786 - acc: 0.9736\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0781 - acc: 0.9746\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0771 - acc: 0.9730\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0669 - acc: 0.9770\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0618 - acc: 0.9792\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 33s 659us/step - loss: 0.0689 - acc: 0.9768\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0446 - acc: 0.9852\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0525 - acc: 0.9828\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0465 - acc: 0.9844\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.0468 - acc: 0.9840\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0531 - acc: 0.9823\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0471 - acc: 0.9841\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0322 - acc: 0.9893\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0329 - acc: 0.9890\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 0.0411 - acc: 0.98640s - loss: 0.0410 - acc: 0.9\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 0.0388 - acc: 0.9875\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.0356 - acc: 0.98862s - loss: 0.0345 - acc: 0.\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0308 - acc: 0.9904\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0300 - acc: 0.9906\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 0.0396 - acc: 0.9879\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0409 - acc: 0.98730s - loss: 0.0408 - acc:\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0246 - acc: 0.9921\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0230 - acc: 0.9925\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0377 - acc: 0.9887\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 33s 659us/step - loss: 0.0320 - acc: 0.9901\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0248 - acc: 0.99221s - l\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0292 - acc: 0.9908\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0186 - acc: 0.9935\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0265 - acc: 0.9914\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.0213 - acc: 0.9930\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0233 - acc: 0.9926\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0253 - acc: 0.9916\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.0196 - acc: 0.9940\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0190 - acc: 0.9939\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0295 - acc: 0.9905\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0266 - acc: 0.9920\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 0.0215 - acc: 0.9934\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0165 - acc: 0.9947\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0172 - acc: 0.9948\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0131 - acc: 0.9954\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0262 - acc: 0.9930\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 0.0225 - acc: 0.9932\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0188 - acc: 0.9942\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0146 - acc: 0.9954\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0191 - acc: 0.9943\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0200 - acc: 0.9937\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0156 - acc: 0.9950\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0119 - acc: 0.9963\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.0174 - acc: 0.9946\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0220 - acc: 0.9935\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0197 - acc: 0.9941\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0146 - acc: 0.9953\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0142 - acc: 0.9961\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0147 - acc: 0.9960\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0169 - acc: 0.9955\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0176 - acc: 0.9949\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0206 - acc: 0.9936\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 33s 664us/step - loss: 0.0154 - acc: 0.99491s - loss: 0.01\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0100 - acc: 0.9971\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0091 - acc: 0.9972\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.0121 - acc: 0.9967\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0161 - acc: 0.9953\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0199 - acc: 0.99450s - loss: 0.0200 - acc: 0.994\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0176 - acc: 0.9947\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0130 - acc: 0.9961\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0113 - acc: 0.9967\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0112 - acc: 0.9965\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0137 - acc: 0.9960\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0208 - acc: 0.9945\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0147 - acc: 0.99561s - loss:\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.0064 - acc: 0.9980\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0101 - acc: 0.9970- ETA: 1s - loss: 0.\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0142 - acc: 0.9959\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0124 - acc: 0.9966\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.0130 - acc: 0.9959\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0152 - acc: 0.9955\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0134 - acc: 0.9963\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0098 - acc: 0.9974\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0107 - acc: 0.9969\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0121 - acc: 0.9963\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0111 - acc: 0.9972\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0188 - acc: 0.9947\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0109 - acc: 0.9973\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0134 - acc: 0.9963\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0153 - acc: 0.9957\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 0.0099 - acc: 0.997 - 33s 660us/step - loss: 0.0099 - acc: 0.9972\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 33s 661us/step - loss: 0.0076 - acc: 0.9977\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.0123 - acc: 0.99641s - loss: \n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 0.0124 - acc: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb76418b7b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(filters = 32, kernel_size = (3, 3), padding = 'same',input_shape = (32, 32, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(filters = 64, kernel_size = (3, 3), padding = 'same', activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim = 100, activation = 'relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim = 10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.2453935e-05, 1.7829918e-13, 6.3874737e-05, 5.4921710e-01,\n",
       "        4.4222298e-01, 4.8794540e-13, 8.3683655e-03, 1.8103880e-07,\n",
       "        4.3855183e-05, 1.1139457e-05]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final prediction\n",
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
